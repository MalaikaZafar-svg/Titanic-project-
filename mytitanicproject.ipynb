{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e61c00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T02:17:01.582646Z",
     "iopub.status.busy": "2025-03-10T02:17:01.582285Z",
     "iopub.status.idle": "2025-03-10T02:19:03.339304Z",
     "shell.execute_reply": "2025-03-10T02:19:03.337764Z"
    },
    "papermill": {
     "duration": 121.763512,
     "end_time": "2025-03-10T02:19:03.342217",
     "exception": false,
     "start_time": "2025-03-10T02:17:01.578705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Best Parameters: {'ensemble__rf__max_depth': 15, 'ensemble__rf__n_estimators': 200, 'ensemble__svc__C': 1, 'ensemble__xgb__learning_rate': 0.1, 'ensemble__xgb__max_depth': 3}\n",
      "Best CV Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(data, train_params):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Basic feature engineering\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Title extraction with normalization\n",
    "    df['Title'] = df['Name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False).str.strip()\n",
    "    df['Title'] = df['Title'].replace(train_params['rare_titles'], 'Rare')\n",
    "    df['Title'] = df['Title'].map(train_params['title_mapping']).fillna(-1)\n",
    "    \n",
    "    # Cabin-based features\n",
    "    df['Deck'] = df['Cabin'].str[0].fillna('Unknown')\n",
    "    df['Deck'] = df['Deck'].map(train_params['deck_mapping'])\n",
    "    \n",
    "    # Fare transformations\n",
    "    df['Fare'] = df['Fare'].fillna(train_params['fare_median'])\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    \n",
    "    # Age processing\n",
    "    df['Age'] = df['Age'].fillna(train_params['age_median'])\n",
    "    df['Age'] = df['Age'].clip(upper=train_params['age_clip'])\n",
    "    \n",
    "    # Categorical encoding\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2}).fillna(1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    return df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Fare'])\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/c/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/c/titanic/test.csv\")\n",
    "\n",
    "# Calculate training parameters for preprocessing\n",
    "train_params = {\n",
    "    'title_mapping': {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4},\n",
    "    'rare_titles': ['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Lady', 'Jonkheer', 'Dona', 'Don', 'Mme', 'Ms', 'Capt', 'Mlle', 'Sir'],\n",
    "    'deck_mapping': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7, 'Unknown': -1},\n",
    "    'fare_median': train['Fare'].median(),\n",
    "    'age_median': train['Age'].median(),\n",
    "    'age_clip': train['Age'].quantile(0.99)\n",
    "}\n",
    "\n",
    "# Preprocess data\n",
    "X_train = preprocess_data(train, train_params). drop(columns=['Survived'])\n",
    "y_train = train['Survived']\n",
    "X_test = preprocess_data(test, train_params)\n",
    "X_train = X_train[sorted(X_train.columns)]\n",
    "X_test = X_test[sorted(X_train.columns)]\n",
    "# Create model pipeline\n",
    "pipeline = imbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "    ('ensemble', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(random_state=42)),\n",
    "            ('xgb', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
    "            ('svc', SVC(probability=True, random_state=42))\n",
    "        ],\n",
    "        voting='soft'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'ensemble__rf__n_estimators': [200, 300],\n",
    "    'ensemble__rf__max_depth': [None, 15],\n",
    "    'ensemble__xgb__max_depth': [3, 5],\n",
    "    'ensemble__xgb__learning_rate': [0.01, 0.1],\n",
    "    'ensemble__svc__C': [1, 10]\n",
    "}\n",
    "\n",
    "# Configure and run grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Final evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Generate predictions\n",
    "test_pred = best_model.predict(X_test)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_pred\n",
    "})\n",
    "submission. to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    },
    {
     "datasetId": 4450,
     "sourceId": 6828,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 11657,
     "sourceId": 16098,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1818188,
     "sourceId": 2965537,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2855238,
     "sourceId": 4923714,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4236507,
     "sourceId": 7302359,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6560109,
     "sourceId": 10598627,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 4177385,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 14232301,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 125.426429,
   "end_time": "2025-03-10T02:19:04.166079",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-10T02:16:58.739650",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
