{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"},{"sourceId":6828,"sourceType":"datasetVersion","datasetId":4450},{"sourceId":16098,"sourceType":"datasetVersion","datasetId":11657},{"sourceId":2965537,"sourceType":"datasetVersion","datasetId":1818188},{"sourceId":4923714,"sourceType":"datasetVersion","datasetId":2855238},{"sourceId":7302359,"sourceType":"datasetVersion","datasetId":4236507},{"sourceId":10598627,"sourceType":"datasetVersion","datasetId":6560109},{"sourceId":4177385,"sourceType":"kernelVersion"},{"sourceId":14232301,"sourceType":"kernelVersion"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as imbPipeline\n\n# Preprocessing function\ndef preprocess_data(data, train_params):\n    df = data.copy()\n    \n    # Basic feature engineering\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n    \n    # Title extraction with normalization\n    df['Title'] = df['Name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False).str.strip()\n    df['Title'] = df['Title'].replace(train_params['rare_titles'], 'Rare')\n    df['Title'] = df['Title'].map(train_params['title_mapping']).fillna(-1)\n    \n    # Cabin-based features\n    df['Deck'] = df['Cabin'].str[0].fillna('Unknown')\n    df['Deck'] = df['Deck'].map(train_params['deck_mapping'])\n    \n    # Fare transformations\n    df['Fare'] = df['Fare'].fillna(train_params['fare_median'])\n    df['LogFare'] = np.log1p(df['Fare'])\n    \n    # Age processing\n    df['Age'] = df['Age'].fillna(train_params['age_median'])\n    df['Age'] = df['Age'].clip(upper=train_params['age_clip'])\n    \n    # Categorical encoding\n    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n    df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2}).fillna(1)\n    \n    # Drop unnecessary columns\n    return df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Fare'])\n\n# Load data\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\n\n# Calculate training parameters for preprocessing\ntrain_params = {\n    'title_mapping': {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4},\n    'rare_titles': ['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Lady', 'Jonkheer', 'Dona', 'Don', 'Mme', 'Ms', 'Capt', 'Mlle', 'Sir'],\n    'deck_mapping': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7, 'Unknown': -1},\n    'fare_median': train['Fare'].median(),\n    'age_median': train['Age'].median(),\n    'age_clip': train['Age'].quantile(0.99)\n}\n\n# Preprocess data\nX_train = preprocess_data(train, train_params)\ny_train = train['Survived']\nX_test = preprocess_data(test, train_params)\n\n# Create model pipeline\npipeline = imbPipeline([\n    ('smote', SMOTE(random_state=42)),\n    ('selector', SelectKBest(mutual_info_classif, k=12)),\n    ('ensemble', VotingClassifier(\n        estimators=[\n            ('rf', RandomForestClassifier(random_state=42)),\n            ('xgb', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')),\n            ('svc', SVC(probability=True, random_state=42))\n        ],\n        voting='soft'\n    ))\n])\n\n# Hyperparameter grid\nparam_grid = {\n    'ensemble__rf__n_estimators': [200, 300],\n    'ensemble__rf__max_depth': [None, 15],\n    'ensemble__xgb__max_depth': [3, 5],\n    'ensemble__xgb__learning_rate': [0.01, 0.1],\n    'ensemble__svc__C': [1, 10]\n}\n\n# Configure and run grid search\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n    scoring='accuracy',\n    n_jobs=-1,\n    verbose=1\n)\ngrid_search.fit(X_train, y_train)\n\n# Final evaluation\nbest_model = grid_search.best_estimator_\nprint(f\"Best Parameters: {grid_search.best_params_}\")\nprint(f\"Best CV Accuracy: {grid_search.best_score_:.2f}\")\n\n# Generate predictions\ntest_pred = best_model.predict(X_test)\nsubmission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': test_pred\n})\nsubmission.to_csv(\"improved_submission.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}